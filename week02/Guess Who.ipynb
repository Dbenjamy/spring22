{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "# from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "\n",
    "# from sklearn.preprocessing import KBinsDiscretizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/sai-byui/spring22/main/week02/AI%20Society%20Survey.csv'\n",
    "data = pd.read_csv(url)\n",
    "data.drop(columns=['Timestamp'], inplace=True)\n",
    "\n",
    "# Drop nan's (b/c we don't like those)\n",
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns = [\"height\", \"age\", \"gender\", \"shoe_size\", \"dress\", \"twilight\", \"horse_duck\", \"office\"]\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "gender = pd.get_dummies(data['gender'])\n",
    "dress = pd.get_dummies(data['dress'])\n",
    "twilight = pd.get_dummies(data['twilight'])\n",
    "horse_duck = pd.get_dummies(data['horse_duck'])\n",
    "office = pd.get_dummies(data['office'])\n",
    "\n",
    "data = pd.concat([data, dress, twilight, horse_duck, office], axis=1)\n",
    "data.drop(columns=['dress', 'twilight', 'horse_duck', 'office'], inplace=True)\n",
    "\n",
    "data['gender'] = le.fit_transform(data['gender'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets make sure our heights are realistic (index 18 was 510)\n",
    "data = data.query(\"height <= 100\").astype('float')\n",
    "\n",
    "# Create a new correlated feature using shoe size and height\n",
    "data['shoe_height'] = data.shoe_size * data.height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out our feature correlations\n",
    "import seaborn as sns\n",
    "sns.heatmap(data.corr())\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(columns=['gender'])\n",
    "y = data['gender']\n",
    "\n",
    "X, X_dev, y, y_dev = train_test_split(X, y, random_state=42, train_size= .8)\n",
    "X, X_test, y, y_test = train_test_split(X, y, random_state=42, train_size= .8)\n",
    "print(len(X), len(X_dev), len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['gender'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier()\n",
    "model.fit(X, y)\n",
    "\n",
    "y_hat = model.predict(X_dev)\n",
    "y_holdout = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_curve(model, X_dev, y_dev)\n",
    "print(classification_report(y_dev, y_hat));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "importance = model.feature_importances_\n",
    "\n",
    "df = pd.DataFrame(list(zip(importance, X.columns.to_list())),\n",
    "                  columns=['importance', 'feature'])\n",
    "\n",
    "df = df.sort_values(by='importance', ascending=False)\n",
    "sns.set(rc={'figure.figsize': (11.7, 8.27)})\n",
    "sns.barplot(data=df, x='importance', y='feature');"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
